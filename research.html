---
layout: page
title: Research
---

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        .table {
            width: 100%;
            border-collapse: collapse;
        }
        .table td {
            padding: 8px;
            border-right: none;
            border-left: none;
        }
        .table td:last-child {
            border-right: none;
            border-left: none;
            border-top: none;
            border-bottom: none;
        }

    </style>
</head>


<body>

<div style="border: 1px solid #ddd; background-color: #a6a6a6; padding: 15px; margin-bottom: 15px;">
    <h3>Research Students</h3>
</div>

<table class="table">
    <tr>
        <td><strong>Shaheer Afridi</strong></td>
        <td>"Medical Imaging Segmentation through State-of-the-art Deep Learning Technique using 3D volumetric Data"</td>
    </tr>
    <tr>
        <td><strong>Utsab Chalise</strong></td>
        <td>"Generating Brain MRI Images for Spatial and Volumetric Upsampling Using Diffusion Techniques"</td>
    </tr>
    <tr>
        <td><strong>Akintade Egbetakin</strong></td>
        <td>"Computer Vision and Deep Learning for the Detection of COVID-19, Pneumonia, and Tuberculosis using Chest X-ray Images"</td>
    </tr>
    <tr>
        <td><strong>Efoma Ibude</strong></td>
        <td>"Satellite Image Super Resolution Using GAN Techniques"</td>
    </tr>
</table>

<br>



<div style="border: 1px solid #ddd; background-color: #a6a6a6; padding: 15px; margin-bottom: 15px;">
    <h3>Datasets</h3>
</div>

<table border="0" cellspacing="0" cellpadding="0" style="width: 100%;">
    <tr>
        <td style="width: 25%;">
            <figure>
                <figcaption>
                    <a href="https://saras-esad.grand-challenge.org/download/">SARAS-ESAD Dataset</a>
                </figcaption><br><br>
                <img src="/assets/img/paper/esad_dataset.png" align="top" style="width: 100%;">
            </figure>
        </td>
        <td style="width: 75%;">
            The SARAS-ESAD is a surgical action detection dataset developed to build AI systems to assist surgeons 
            during minimally invasive surgery. The system needs to detect and understand the actions performed by 
            the surgeons in endoscopic videos in real-time. The datasets provide action information and locations 
            annotations for surgical tools on recoded videos during real surgeries. The dataset contains 21 action 
            classes and each frame is annotated for all the actions being performed in that instance. The dataset 
            is divided into training, validation, and test sets. The training data contains over 22,000 frames 
            with annotations for over 28,000 actions. The dataset was released in SARAS-ESAD challenge and can 
            be downloaded from the challenge website. 
        </td>
    </tr>
    <tr>
        <td style="width: 25%;">
            <figure>
                <figcaption>
                    <a href="https://saras-mesad.grand-challenge.org/download/">SARAS-MESAD Dataset</a>
                </figcaption><br><br>
                <img src="/assets/img/paper/mesad_dataset.png" align="top" style="width: 100%;">
            </figure>
        </td>
        <td style="width: 75%;">
            The SARAS-ESAD is a surgical action detection dataset developed to build AI systems to assist surgeons 
            during minimally invasive surgery. The system needs to detect and understand the actions performed by 
            the surgeons in endoscopic videos in real-time. The datasets provide action information and locations 
            annotations for surgical tools on recoded videos during real surgeries. The dataset contains 21 action 
            classes and each frame is annotated for all the actions being performed in that instance. The dataset 
            is divided into training, validation, and test sets. The training data contains over 22,000 frames 
            with annotations for over 28,000 actions. The dataset was released in SARAS-ESAD challenge and can 
            be downloaded from the challenge website. 
        </td>
    </tr>
</table>


<br>



<div style="border: 1px solid #ddd; background-color: #a6a6a6; padding: 15px; margin-bottom: 15px;">
    <h3>Softwares</h3>
</div>


<table border="0" cellspacing="0" cellpadding="0" style="width: 100%;">
    <tr>
        <div style= "display: flex; width: 100%;">
            <div style= "flex: 1; padding: 5px; width: 100%;">
                <iframe src="https://drive.google.com/file/d/1Ey32z2bgyEDJ0YEFsLnscKr91nQE6dvB/preview" 
                width="320" height="200" allow="autoplay" style="display: inline-block; margin: 10px;"></iframe>
            </div>
            <div style= "flex: 1; padding: 5px;">
                Write your description about the video content here. You can add multiple paragraphs, 
                    headings, or other elements to structure your details. Write your description about the video content here. You can add multiple paragraphs, 
                    headings, or other elements to structure your details. Write your description about the video content here. You can add multiple paragraphs, 
                    headings, or other elements to structure your details. Write your description about the video content here. You can add multiple paragraphs, 
                    headings, or other elements to structure your details. Write your description about the video content here. You can add multiple paragraphs, 
                    headings, or other elements to structure your details.
            </div>
        </div>
    </tr>

    <tr>
        <div style= "display: flex; width: 100%;">
            <div style= "flex: 1; padding: 5px; width: 100%;">
                <iframe src="https://drive.google.com/file/d/1Ey32z2bgyEDJ0YEFsLnscKr91nQE6dvB/preview" 
                width="320" height="200" allow="autoplay" style="display: inline-block; margin: 10px;"></iframe>
            </div>
            <div style= "flex: 1; padding: 5px;">
                Write your description about the video content here. You can add multiple paragraphs, 
                    headings, or other elements to structure your details. Write your description about the video content here. You can add multiple paragraphs, 
                    headings, or other elements to structure your details. Write your description about the video content here. You can add multiple paragraphs, 
                    headings, or other elements to structure your details. Write your description about the video content here. You can add multiple paragraphs, 
                    headings, or other elements to structure your details. Write your description about the video content here. You can add multiple paragraphs, 
                    headings, or other elements to structure your details.
            </div>
        </div>
    </tr>
</table>



<br>




<div style="border: 1px solid #ddd; background-color: #a6a6a6; padding: 15px; margin-bottom: 15px;">
    <h3>Key Publications</h3>
</div>

<table border="0" cellspacing="0" cellpadding="0" style="width: 100%;">
    <tr>
        <td style="width: 25%;">
            <img src="/assets/img/paper/lisa.png" align="top" style="width: 100%;">
        </td>
        <td style="width: 75%;">
            <b> Linearized sigmoidal activation: A novel activation function with tractable non-linear 
                characteristics to boost representation capability</b> <br>
            <i>  Vivek Singh Bawa and Vinay Kumar </i> <br>
            <i> Expert Systems with Applications, 2019 </i> <br>
            [<a href="https://www.sciencedirect.com/science/article/pii/S0957417418307619">link</a>]
        </td>
    </tr>

    <tr>
        <td style="width: 25%;">
            <img src="/assets/img/paper/esad.png" align="top" style="width: 100%;">
        </td>
        <td style="width: 75%;">
            <b> The saras endoscopic surgeon action detection (esad) dataset: Challenges and methods</b> <br>
            <i> Vivek Singh Bawa, Gurkirt Singh, Francis KapingA, Inna Skarga-Bandurova, Elettra Oleari, 
                Alice Leporini, Carmela Landolfo, Pengfei Zhao, Xi Xiang, Gongning Luo, Kuanquan Wang, 
                Liangzhi Li, Bowen Wang, Shang Zhao, Li Li, Armando Stabile, Francesco Setti, 
                Riccardo Muradore, Fabio Cuzzolin</i> <br>
            <i> ArXiv, 2021 </i> <br>
            [<a href="https://arxiv.org/pdf/2104.03178">pdf</a>]
        </td>
    </tr>

    <tr>
        <td style="width: 25%;">
            <img src="/assets/img/paper/facial.png" align="top" style="width: 100%;">
        </td>
        <td style="width: 75%;">
            <b>An automatic multimedia likability prediction system based on facial expression of observer</b> <br>
            <i>Vivek Singh Bawa, Shailza Sharma, Mohammed Usman, Abhimat Gupta, Vinay Kumar</i> <br>
            <i>IEEE Access, 2021 </i> <br>
            [<a href="https://ieeexplore.ieee.org/abstract/document/9504548">link</a>] 
        </td>
    </tr>
</table>

</body>
